---
layout: post
title: "Deep Learning: ch 6. Deep Feedforward Network"
tags: [Deep Learning]
comments: true
---

# Introduction

![image](https://user-images.githubusercontent.com/45325895/51292871-bac93d80-1a4f-11e9-8a5d-460624182b5d.png){: .center-image}  

Deep feedforward network는 feedforward neural network 또는 multilayer perceptron이라고도 불리며, 딥러닝 모형의 가장 기본이 되는 모형이다. feedforward network의 목적은 어떤 미지의 함수 $f^\ast$를 근사하는 함수 $f$를 만드는 것이다. 예를 들어, 만약 $f^\ast
$가 classifier라면, $y=f^\ast (x)$는 input $x$를 받아 class $y$를 반환하는 함수일 것이다. feedforward network는 이와 같은 $f$가 $f^\ast$를 가장 잘 근사하는 함수가 되도록 $y=f(x;\theta)$의 parameter, $\theta$를 학습한다.  

Deep feedforward network 혹은 feedforward neural network라는 이름의 의미를 하나하나 살펴보며, 그 특징에 대해 알아보자. 
  
  
**Feedforward**:  
 * 앞으로(forward) 정보를 준다(feed)는 이름에서 알 수 있듯이, deep feedforward network는 그 output이 다시 input이 되거나, 혹은 다음 input에 영향을 주는 **feedback 연결**이 없다. 이와 같은 feedback이 있는 neural network 모형은 뒤의 Recurrent Neural Network에서 살펴볼 것이다.  
  
**Network**:  
 * Deep feedforward network는 많은 수의 서로 다른 함수들을 합성하여 나타내기 때문에 **network**로 불린다. 예를 들어, 세 개의 함수 $f^{(1)},f^{(2)},f^{(3)}$으로 $f(x)=f^{(3)}(f^{(2)}(f^{(1)}(x)))$와 같이 chain 형식의 함수를 만든다고 해보자. 이와 같은 chain 형식은 neural network에서 매우 빈번하게 쓰이며, 우리는 $f^{(i)}$를 $i$ 번째 **layer**라고 부른다. 이러한 **layer**들, $f^{(1)}(x),f^{(2)}(f^{(1)}(x)), f^{(3)}(f^{(2)}(f^{(1)}(x)))$은 각각 모두 벡터일텐데, 이 layer 벡터들의 차원(벡터의 길이)을 해당 layer의 **width**라고 부른다.  
  
**Deep**:  
 * Deep feedforward network는 주로 여러 함수의 합성 chain 형태로 나타낼 수 있다고 했는데, 그 chain의 길이를 **모형의 depth**라고 부른다. 따라서 **깊은(Deep)** learning이라는 표현은 합성된 함수의 chain의 길이가 길다는 점, 즉, layer의 수가 많은 network라는 점에서 유래한 것이다.  
  
**Neural**:  
 * 이러한 deep feedforward network는 feedforward **neural** network라고도 불리는데, 그 이유는 neural network의 함수 구조가 신경과학에서 일부 영향을 받았기 때문이다. 각 layer 벡터 내의 원소들은 각각 신경세포(neuron) 하나에 비유된다. 또한, 신경세포는 이전 신경세포로부터 신호를 받아 다음 신경세포로 신호를 전달하는데, 이 점이 이전 layer에서 input을 받아 다음 layer로 output을 전달하는 deep feedforward network와 매우 닮아있다. 다만, 그렇다고 해서 deep feedforward network의 목적이 인간의 뇌를 모방하는 알고리즘을 만드는 것은 아니다.  
  
추가로, 몇 가지 필요한 개념들에 대해 더 정리해보자.  
  
**output layer**:  
 * feedforward network의 마지막 layer는 전체 함수의 output을 최종적으로 출력하는 layer이기 때문에 **output layer**라고 부른다.  
  
**network를 훈련(train)**:  
 * 우리는 **network를 훈련(train)**시킨다는 표현을 많이 접할 것이다. 이는 $f$가 $f^*$를 잘 근사하는 함수가 되도록 **$y=f(x;\theta)$의 parameter, $\theta$의 최적 값을 결정한다**는 뜻이다.  
  
**Training data**:  
  
 * **Training data**는 **network를 훈련**시키기 위하여 사용하는 데이터셋이다. $(x_1,y_1),...,(x_N,y_N)$과 같이 input $x_i$와 실제 label $y_i$가 짝을 이루고 있다. 이 때 $y_i$는 우리가 추정하고자 하는 true function $f^\ast$로부터 만들어진 true label이므로 $y_i=f^\ast (x_i)$이다. 우리가 구축한 함수 $f$로부터 얻은 output $f(x_i)$가 $f^\ast (x_i)$와 최대한 비슷해지는 것을 목표로, **network를 훈련(train)**시킨다.  
  
**Hidden layers**:  
  
 * training example들은 $f$의 output layer가 어떤 값을 반환해야 하는지에 대한 정보를 준다. 하지만, input layer와 output layer 사이의 layer들이 정확히 어떻게 행동해야 할지에 대해서는 아무런 정보를 주지 않는다. 실제로 network를 훈련시켜 최적의 parameter, $\hat{\theta}$를 찾은 뒤에도, input layer와 output layer 사이의 layer들의 행동을 설명할 수는 없다. 따라서 이 layer들을 **hidden layer**라고 부른다.
  
<br>
  
  
# 6.1 Example: Learning XOR
Feedforward network에 대한 이해를 좀 더 확실히 하기 위해, feedforward network로 XOR 함수를 학습하는 과정을 살펴보자. XOR 함수는 두 개의 input을 받아 하나의 output을 반환하는 함수이며, 이 때 input과 output은 모두 binary value($0$ or $1$)를 갖는다.  

![image](https://user-images.githubusercontent.com/45325895/51293056-6f635f00-1a50-11e9-97ef-e73565b1be12.png){: .center-image}  

추정하고자 하는 target 함수는 XOR 함수이기 때문에, $y=f^\ast (x)$는 위의 사진에 나타난 XOR 함수를 의미한다.($x$는 $2$차원 벡터로 이루어진 input일 것이다.) 우리는 feedforward network $y=f(x;\theta)$를 만들고, $f$가 $f^\ast $와 가장 비슷해지는 $\theta$의 최적 값을 찾는 방식으로 $f$를 학습시킬 것이다.  

우리는 우리의 feedforward network $f$가 가능한 네 개의 input 점 모두에서 올바른 output을 반환하기를 원한다. 따라서 이 네 input 점과 각각 그에 맞는 XOR 값이 training data로 주어졌다고 가정하자.

$$
\mathbb{X}= \{ [0,0]^T, [0,1]^T, [1,0]^T, [1,1]^T \}
$$


그렇다면 이제 남은 작업은 이 feedforward network를 학습시키는 것, 다시 말해서 $y=f(x;\theta)$의 parameter, $\theta$의 최적 값을 결정하는 것이다. 어떻게 $\theta$의 최적 값을 결정하면 좋을까?  

일반적인 회귀분석에서는 MSE(Mean Squared Error)를 **Cost function**으로 설정하고, 이를 최소화하는 방법으로 최적의 회귀계수 추정치를 얻는다. 비록 binary data에서 MSE는 좋은 Cost function이 아니지만, 간단하게 회귀분석과 유사하게 이 경우에도 MSE를 Cost function으로 설정하고 feedforward network를 학습시켜보자. training set $\mathbb{X}$ 를 이용하여 MSE를 구하면 다음과 같다. 

$$
J(\theta)= \frac{1}{4} \sum_{x \in \mathbb{X}} (f^\ast (x)-f(x;\theta))^2
$$

이제 우리의 모형 $f$의 형태를 결정하고, 위 MSE 식을 최소화하는 parameter $\theta$를 찾으면 된다. 아래와 같은 구조의 feedforward network를 생각해보자.

![image](https://user-images.githubusercontent.com/45325895/51293671-4395a880-1a53-11e9-97f2-76b8993dfba6.png){: .center-image}

이를 한 input, $x$에 대한 식으로 나타내면 아래와 같다. 

$$
h=f^{(1)}(x;W,c)=g(W^Tx+c) \enspace , \enspace \enspace y=f^{(2)}(h;w,b)=w^Th+b
$$

$$
y=f^{(2)}(f^{(1)}(x))=f(x;W,c,w,b)
$$

위 식이 다소 복잡해보이지만 줄거리는 다음과 같다. 차근차근 받아들여보자.
 * 한 layer에서 다음 layer로 신호를 전달할 때는, 이전 layer의 원소들의 output을 **가중합(weighted sum)**하여 전달한다. 
 * 각 layer는 이전 layer로부터 전달받은 신호를 바로 output으로 다음 layer에 전달하는 것이 아니라, 가중합으로 전달받은 신호를 어떤 함수 $g$에 넣은 결과값을 다음 layer로 전달한다. 이를 **Activation function**이라고 한다. **Activation function은 들어온 정보를 바탕으로 output을 계산해주는 함수이다.**
 * 가중합된 input은 **bias**라는 상수를 더해서 **Activation function**에 입력된다.

여전히 이해가 잘 가지 않을 것이다. 이 내용을 위 그림 상의 $h$ layer의 첫 번째 node, $h_1$의 기준에서 다시 설명해보겠다.
 * $h_1$은 input layer의 두 node로부터 $x_1$과 $x_2$을 **가중합(weighted sum)** 한 형태로 정보를 받는다. ㅡ $w_{11}x_1+w_{21}x_2$
 * 이 **가중합(weighted sum)**으로 들어온 신호가 $h_1$ node의 output으로 바로 다음 layer인 output layer $y$에 전달되는 것이 아니다.
 * **가중합(weighted sum)**으로 들어온 신호, $w_{11}x_1+w_{21}x_2$를 **activation function** $g$에 넣어 출력된 결과가, $h_1$ node의 output이 되어 output layer $y$에 전달된다.
 * 즉 $h_1$ node의 output은 아래와 같다. 여기서 $c_1$은 activation function에 가중합 된 input이 입력되기 전 더해지는 **bias**이다.

$$
h_1 = g(w_{11}x_1+w_{21}x_2+c_1)
$$

마찬가지로 $h_2$ node의 output도 아래와 같이 구할 수 있다.

$$
h_2 = g(w_{12}x_1+w_{22}x_2+c_2)
$$

이를 벡터 표현으로 한 번에 나타낸 것이 위의 식이다.

$$
h=
\left[ {\begin{array}{c}
   h_1 \\
   h_2 \\
  \end{array} } \right]
=
\left[ {\begin{array}{c}
   g(w_{11}x_1+w_{21}x_2+c_1) \\
   g(w_{12}x_1+w_{22}x_2+c_2) \\
  \end{array} } \right]
=g \Big(
\left[ {\begin{array}{c}
   w_{11}x_1+w_{21}x_2+c_1 \\
   w_{12}x_1+w_{22}x_2+c_2 \\
  \end{array} } \right]
\Big)
$$

$$
=g \Big(
\left[ {\begin{array}{cc}
   w_{11} w_{12} \\
   w_{21} w_{22} \\
  \end{array} } \right]
\left[ {\begin{array}{c}
   x_1 \\
   x_2 \\
  \end{array} } \right]
+
\left[ {\begin{array}{c}
   c_1 \\
   c_2 \\
  \end{array} } \right]
\Big)
=g(W^T x+c)
$$

이와 같은 표기를 이용하여 output layer로 전달된 후의 최종 식을 정리하면 아래와 같다. 

$$
y=f^{(2)}(h;w,b)=w^Th+b=w^T g(W^Tx+c)+b
$$


Activation function의 형태만 specify한다면, XOR함수 $f^\ast $를 근사하는 함수 $f$의 형태를 완전히 정한 것이 된다. 위에서도 설명했듯이, **Activation function은 들어온 정보를 바탕으로 output을 계산해주는 함수이다.** Neural network에서 쓰이는 activation function은 크게 아래와 같은 예시들이 있다. activation function은 그 output 값의 범위나 모양에 의해 서로 다른 특징을 보이는데, 어느 경우에 어떤 activation function을 사용하면 좋은지에 대한 자세한 논의는 추후 다루기로 한다.  
 * Logistic 함수 : $y={1}/{(1+e^{-x})}$

![image](https://user-images.githubusercontent.com/45325895/51297339-46989500-1a63-11e9-9972-b820c83a2286.png){: .center-image}

 * Hyperbolic tangent : $y=tanh(x)$

![image](https://user-images.githubusercontent.com/45325895/51297278-f9b4be80-1a62-11e9-89c7-73e8b2b3a335.png){: .center-image}

 * ReLU 함수 : $y=max(0,x)$

![image](https://user-images.githubusercontent.com/45325895/51297446-a55e0e80-1a63-11e9-8619-6355ee1fb3ce.png){: .center-image}
  
또한, **bias**는 **Activation function**을 input 축 방향으로 평행이동 시키는 상수인 것을 알 수 있다. 즉, 가중합의 형태로 들어온 신호가 일정 수준 이상일 때 Activation function이 반응하도록 혹은 특정 값 이상의 output을 만들도록, **threshold**를 지정해주는 상수인 것이다.

![image](https://user-images.githubusercontent.com/45325895/51297578-2917fb00-1a64-11e9-967b-ae41e0667b6f.png){: .center-image}

만약 XOR함수 추정 문제에서 우리가 ReLU 함수를 Activation function으로 사용하기로 결정했다면, XOR함수 $f^*$를 근사하는 우리의 feedforward network 함수 $f$는 다음과 같다.

$$
y=w^Th+b=w^T max(0,W^Tx+c)+b
$$

이와 같은 $f$의 식을 이용해, Cost function을 최소화하는 parameter, $\hat W,\hat c,\hat w,\hat b$를 구하면 XOR 함수를 근사하는 feedforward network의 학습을 완료한 것이다. 이 예시의 실제 계산과정은 다루지 않겠다.  
  
이 예시는 training example이 4개이고, parameter가 총 10개인 매우 간단한 예시이다.($W$는 $2\times 2$행렬, $c$는 $2\times 1$벡터, ....) 그런데 실제 데이터 분석에 neural network를 적용한다면, **수십억개의 training example을 이용해 수십억개의 parameter를 추정해야 할 것이다.** 따라서 이 예시에서와 같이 단순히 Loss function을 최소화하는 parameter의 값을 일계조건을 이용하여 **analytic하게 구하는 것은 불가능하다.** 따라서 우리는 Cost function을 최소화하는 parameter의 값을 구하는 다른 방법을 고려해야 한다.  

<br>
  
  
# 6.2 Gradient-Based Learning

<br>
<br>
<br>
<br>

# Reference
> Goodfellow, I., Bengio, Y., & Courville, A. (2017). Deep learning. Cambridge, MA: MIT Press.
